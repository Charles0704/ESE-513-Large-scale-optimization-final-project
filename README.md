## 1.INTRODUCTIONï¼š  
Sparse regression has become highly valuable across a wide range of applications due to its enhanced model interpretability and ability
to improve efficiency by selecting only the most relevant features.
A core optimization technique in sparse regression is coordinate descent, particularly effective in methods like LASSO and Elastic Net,
which promote sparsity. This technique is essential for its computational efficiency, scalability, reliable convergence properties, and
suitability for handling non-differentiable functions. In this report,
we explore the application of coordinate descent in LASSO regression, a widely-used approach with convex loss function for achieving
sparse solutions. We also conduct experiments to implement coordinate descent for LASSO, and analyze the results.  

## 2.BACKGROUND  

### 2.1. Sparse Regression  

### 2.2. LASSO  


## 3. METHODOLOGY  

## 4. EXPERIMENT  










